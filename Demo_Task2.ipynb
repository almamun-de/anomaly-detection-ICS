{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46483a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc4e3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_statistic(obs_one, obs_two):\n",
    "    cdf_one = np.sort(obs_one)\n",
    "    cdf_two = np.sort(obs_two)\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    d = 0.0\n",
    "    fn1 = 0.0\n",
    "    fn2 = 0.0\n",
    "    l1 = float(len(cdf_one))\n",
    "    l2 = float(len(cdf_two))\n",
    "\n",
    "    while (i < len(cdf_one) and j < len(cdf_two)):\n",
    "        d1 = cdf_one[i]\n",
    "        d2 = cdf_two[j]\n",
    "        if d1 <= d2:\n",
    "            i = i + 1\n",
    "            fn1 = i/l1\n",
    "        if d2 <= d1:\n",
    "            j = j + 1\n",
    "            fn2 = j/l2\n",
    "        dist = abs(fn2 - fn1)\n",
    "        if dist > d:\n",
    "            d = dist\n",
    "\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb1dd60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train, test, scaler):\n",
    "\n",
    "    \n",
    "    normalized_train = pd.DataFrame(\n",
    "        scaler.fit_transform(train),\n",
    "        columns = train.columns\n",
    "    )\n",
    "    \n",
    "    normalized_test = pd.DataFrame(\n",
    "        scaler.transform(test),\n",
    "        columns = test.columns\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    return normalized_train, normalized_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54431e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_result(ks_train_df, ks_test_df):\n",
    "\n",
    "    ks_list = []\n",
    "    for sensor in ks_train_df.columns:\n",
    "\n",
    "        n = ks_statistic(ks_train_df[sensor],ks_test_df[sensor])\n",
    "        ks_list.append([sensor,n])\n",
    "\n",
    "    ks_df = pd.DataFrame(ks_list, columns = ['sensor','ks_statistic'])\n",
    "    \n",
    "    return ks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "550bd662",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_common_states(acturater_list, normalized_train_df, normalized_test_df):\n",
    "\n",
    "    train_sys_states = list(normalized_train_df.value_counts(acturator_list).index)\n",
    "    test_sys_states = list(normalized_test_df.value_counts(acturator_list).index)\n",
    "\n",
    "    common_states = list(set(train_sys_states).intersection(test_sys_states))\n",
    "    \n",
    "    return common_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65673098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reading_by_state(acturator_list, common_state, df):\n",
    "    \n",
    "    new_df = df\n",
    "    i=0\n",
    "    for acturator in acturator_list:\n",
    "        new_df =  new_df[new_df[acturator]==common_state[i]]\n",
    "        i = i+1\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6ec44e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_test(df1, df2, acturator_list):\n",
    "    \n",
    "    sensor_df1 =df1[df1.columns[~df1.columns.isin(acturator_list)]]\n",
    "    sensor_df2 =df2[df2.columns[~df2.columns.isin(acturator_list)]]\n",
    "    \n",
    "    ks_df = ks_result(sensor_df1, sensor_df2)\n",
    "    ks_sum_df = ks_result(sensor_df1, sensor_df2)\n",
    "    ks_sum_df['ks_statistic'] -= ks_sum_df['ks_statistic']\n",
    "    \n",
    "    common_states = get_common_states(acturator_list, df1, df2)\n",
    "    for state in common_states:\n",
    "        new_df1 = extract_reading_by_state(acturator_list, state, df1)\n",
    "        new_df2 = extract_reading_by_state(acturator_list, state, df2)\n",
    "        \n",
    "        new_sensor_df1 = new_df1[new_df1.columns[~new_df1.columns.isin(acturator_list)]]\n",
    "        new_sensor_df2 = new_df2[new_df2.columns[~new_df2.columns.isin(acturator_list)]]\n",
    "        \n",
    "        ks_sum_df['ks_statistic'] += ks_result(new_sensor_df1, new_sensor_df2)['ks_statistic']\n",
    "        \n",
    "    ks_sum_df = ks_sum_df.rename(columns={'ks_statistic':'ks_by_states'})\n",
    "    ks_sum_df['ks_by_states'] /= len(common_states)\n",
    "    \n",
    "    ks_df = ks_df.merge(ks_sum_df,how=\"left\", on='sensor')\n",
    "    \n",
    "    return ks_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39ddb2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_sensor(ks_df):\n",
    "    count1 = len(ks_df[ks_df['ks_statistic']<=0.17])\n",
    "    count2 = len(ks_df[ks_df['ks_by_states']<=0.17])\n",
    "    \n",
    "    return count1, count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4db51783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_common_states(acturator_list, df1, df2):\n",
    "    common_states = get_common_states(acturator_list, df1, df2)\n",
    "    states1 = list(df1.value_counts(acturator_list).index)\n",
    "    states2 = list(df2.value_counts(acturator_list).index)\n",
    "    per_1 = len(common_states)/len(states1)\n",
    "    per_2 = len(common_states)/len(states2)\n",
    "    per_3 = len(common_states)/(len(states1)+len(states2)-len(common_states))\n",
    "    \n",
    "    return per_1, per_2, per_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "953e0e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = 'hai-train1.csv','hai-test1.csv'\n",
    "\n",
    "train_df = pd.read_csv(train)\n",
    "test_df = pd.read_csv(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a2909e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "#if(args.scaler == \"min-max\"):\n",
    "    \n",
    "#    scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16d4e048",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if args.version == '23.05':\n",
    "\n",
    "label_df = pd.read_csv('label-test1.csv')\n",
    "\n",
    "acturator_list = ['P1_PP01AD','P1_PP01AR','P1_PP01BD','P1_PP01BR','P1_PP02D','P1_PP02R','P1_SOL01D','P1_SOL03D','P1_STSP','P2_ATSW_Lamp','P2_AutoGO','P2_Emerg','P2_MASW','P2_MASW_Lamp','P2_ManualGO','P2_OnOff','P2_TripEx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28b1888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove timestamp column since it is not to be processed.\n",
    "train_df = train_df[train_df.columns[train_df.columns!='timestamp']]\n",
    "test_df = test_df[test_df.columns[test_df.columns!='timestamp']]\n",
    "label_df = label_df[label_df.columns[label_df.columns!='timestamp']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43b62d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Columns that are sensor readings.\n",
    "train_sensor_df = train_df[train_df.columns[~train_df.columns.isin(acturator_list)]]\n",
    "test_sensor_df = test_df[test_df.columns[~test_df.columns.isin(acturator_list)]]\n",
    "\n",
    "#Columns that are acturator states.\n",
    "train_acturator_df = train_df[train_df.columns[train_df.columns.isin(acturator_list)]]\n",
    "test_acturator_df = test_df[test_df.columns[test_df.columns.isin(acturator_list)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64132124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize of sensor readings.        \n",
    "ks_train_df, ks_test_df = normalize(train_sensor_df, test_sensor_df, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfc53a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge normalized sensor readings with acturators.\n",
    "ks_train_df = ks_train_df.merge(train_acturator_df,left_index=True, right_index=True)\n",
    "ks_test_df = ks_test_df.merge(test_acturator_df,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c45e5917",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Remove rows that are under attack.\n",
    "ks_test_df = ks_test_df.merge(label_df,left_index=True, right_index=True)\n",
    "ks_test_df = ks_test_df[ks_test_df['label'] == 0]\n",
    "ks_test_df = ks_test_df[ks_test_df.columns[ks_test_df.columns!='label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc828fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_df = ks_test(ks_train_df, ks_test_df, acturator_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf8338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform calculation of ks-statistic with and without considering states.\n",
    "filename = 'hai23.05-'+args.file[0]+'-'+args.file[1]\n",
    "filename1 =filename+'-ks.csv'\n",
    "ks_df.to_csv(filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6695a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "elif args.version == 'end23.05':\n",
    "\n",
    "    label_df = pd.read_csv(args.label)\n",
    "\n",
    "    acturator_list = ['DM-HT01-D','DM-LCV01-MIS','DM-LSH-03','DM-LSH-04','DM-LSH01','DM-LSH02','DM-LSL-04','DM-LSL01','DM-LSL02','DM-PCV01-DEV','DM-PP01-R','DM-PP01A-D','DM-PP01B-D','DM-PP01A-R','DM-PP01B-R','DM-PP02-D','DM-PP02-R','DM-PP04-D','DM-SOL01-D','DM-SOL02-D','DM-SOL03-D','DM-SOL04-D','DM-SS01-RM','DM-ST-SP','DM-SW01-ST','DM-SW02-SP','DM-SW03-EM','DQ03-LCV01-D','DQ04-LCV01-DEV']\n",
    "\n",
    "\n",
    "    train_df = train_df[train_df.columns[train_df.columns!='Timestamp']]\n",
    "    test_df = test_df[test_df.columns[test_df.columns!='Timestamp']]\n",
    "    label_df = label_df[label_df.columns[label_df.columns!='Timestamp']]\n",
    "\n",
    "    train_sensor_df = train_df[train_df.columns[~train_df.columns.isin(acturator_list)]]\n",
    "    test_sensor_df = test_df[test_df.columns[~test_df.columns.isin(acturator_list)]]\n",
    "\n",
    "    train_acturator_df = train_df[train_df.columns[train_df.columns.isin(acturator_list)]]\n",
    "    test_acturator_df = test_df[test_df.columns[test_df.columns.isin(acturator_list)]]\n",
    "\n",
    "        \n",
    "    ks_train_df, ks_test_df = normalize(train_sensor_df, test_sensor_df, scaler)\n",
    "\n",
    "    ks_train_df = ks_train_df.merge(train_acturator_df,left_index=True, right_index=True)\n",
    "    ks_test_df = ks_test_df.merge(test_acturator_df,left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "    ks_test_df = ks_test_df.merge(label_df,left_index=True, right_index=True)\n",
    "    ks_test_df = ks_test_df[ks_test_df['label'] == 0]\n",
    "    ks_test_df = ks_test_df[ks_test_df.columns[ks_test_df.columns!='label']]\n",
    "\n",
    "\n",
    "    ks_df = ks_test(ks_train_df, ks_test_df, acturator_list)\n",
    "    filename = 'end23.05-'+args.file[0]+'-'+args.file[1]\n",
    "    filename1 =filename +'-ks.csv'\n",
    "    ks_df.to_csv(filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757fdbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "elif args.version == '22.04':\n",
    "\n",
    "    \n",
    "    acturator_list = ['P1_PP01AD','P1_PP01AR','P1_PP01BD','P1_PP01BR','P1_PP02D','P1_PP02R','P1_SOL01D','P1_SOL03D','P1_STSP','P2_ATSW_Lamp','P2_AutoGO','P2_Emerg','P2_MASW','P2_MASW_Lamp','P2_ManualGO','P2_OnOff','P2_TripEx']\n",
    "\n",
    "\n",
    "    train_df = train_df[train_df.columns[train_df.columns!='timestamp']]\n",
    "    test_df = test_df[test_df.columns[test_df.columns!='timestamp']]\n",
    "\n",
    "    train_sensor_df = train_df[train_df.columns[~train_df.columns.isin(acturator_list)]]\n",
    "    test_sensor_df = test_df[test_df.columns[~test_df.columns.isin(acturator_list)]]\n",
    "\n",
    "    train_acturator_df = train_df[train_df.columns[train_df.columns.isin(acturator_list)]]\n",
    "    test_acturator_df = test_df[test_df.columns[test_df.columns.isin(acturator_list)]]\n",
    "\n",
    "        \n",
    "    ks_train_df, ks_test_df = normalize(train_sensor_df, test_sensor_df, scaler)\n",
    "\n",
    "    ks_train_df = ks_train_df.merge(train_acturator_df,left_index=True, right_index=True)\n",
    "    ks_test_df = ks_test_df.merge(test_acturator_df,left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "    ks_test_df = ks_test_df[ks_test_df['Attack'] == 0]\n",
    "    ks_test_df = ks_test_df[ks_test_df.columns[ks_test_df.columns!='Attack']]\n",
    "\n",
    "    ks_train_df = ks_train_df[ks_train_df['Attack'] == 0]\n",
    "    ks_train_df = ks_train_df[ks_train_df.columns[ks_train_df.columns!='Attack']]\n",
    "\n",
    "    ks_df = ks_test(ks_train_df, ks_test_df, acturator_list)\n",
    "    filename = 'hai22.04-'+args.file[0]+'-'+args.file[1]\n",
    "    filename1 = filename+'-ks.csv'\n",
    "    ks_df.to_csv(filename1)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    \n",
    "    print(\"Please specify version and run again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b3546",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot some results.        \n",
    "    \n",
    "c1, c2 = count_sensor(ks_df)\n",
    "p1, p2, p3 = percent_common_states(acturator_list, ks_train_df, ks_test_df)\n",
    "    \n",
    "    \n",
    "filename2 = filename+'-sensors.png'\n",
    "x1 = ['no_states','by_states']\n",
    "v1 = [c1,c2]\n",
    "plt.bar(x1,v1)\n",
    "plt.savefig(filename2)\n",
    "plt.close()\n",
    "    \n",
    "filename3 = filename+'-percent.png'\n",
    "x2 = ['common_by_train','common_by_test','common_by_all']\n",
    "v2 = [p1,p2,p3]\n",
    "plt.bar(x2,v2)\n",
    "plt.savefig(filename3)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
